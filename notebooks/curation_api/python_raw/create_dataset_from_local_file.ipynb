{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b68160f6",
   "metadata": {},
   "source": [
    "# Upload a local datafile to add or replace a Dataset in a Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff1ec6e",
   "metadata": {},
   "source": [
    "_\\*\\*The sample code in this notebook limits s3 upload durations to 12 hours. If you think your large file upload may take longer than that, please make use of the `upload_local_datafile` function, whose underlying code supports unlimited upload duration, as seen in the `python/create_dataset_from_local_file.ipynb` notebook.\\*\\*_\n",
    "\n",
    "The script in this notebook performs the upload of a local datafile to a given Collection (as identified by its Collection id), where the datafile becomes a Dataset accessible via the CZ CELLxGENE Discover data portal.\n",
    "\n",
    "In order to use this script, you must have a Curation API key (obtained from upper-righthand dropdown in the CZ CELLxGENE Discover data portal after logging in).\n",
    "\n",
    "_For **new** Datasets_: You must separately create a Dataset (not shown in this notebook). Then, use the returned `dataset_id` as the suffix (append to the `UploadKeyPrefix` returned from the `/s3-upload-credentials` endpoint) of the S3 upload key. See code below, or read more detailed instructions about how to submit Datasets via S3 upload in [the description for the credentials endpoint](https://api.cellxgene.cziscience.com/curation/ui/#/collection/backend.corpora.lambdas.api.v1.curation.collections.collection_id.datasets.upload_s3.get).\n",
    "\n",
    "_For **replacing/updating** existing Datasets_: Uploads to a `dataset_id` for which there already exists a Dataset in the given Collection will result in the existing Dataset being replaced by a new Dataset created from the datafile that you are uploading.\n",
    "\n",
    "\n",
    "You can only add/replace Datasets in _private_ Collections or _private revisions_ of published Collections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cf4dae",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80427063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8964bc",
   "metadata": {},
   "source": [
    "#### <font color='#bc00b0'>Please fill in the required values:</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73c969a",
   "metadata": {},
   "source": [
    "<font color='#bc00b0'>(Required) Provide the path to your api key file</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a2424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key_file_path = \"path/to/api-key.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e84d52e",
   "metadata": {},
   "source": [
    "<font color='#bc00b0'>(Required) Provide the absolute path to the h5ad datafile to upload</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce19b8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/absolute/path/to-datafile.h5ad\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463870f1",
   "metadata": {},
   "source": [
    "<font color='#bc00b0'>(Required) Enter the id of the Collection to which you wish to add this datafile as a Dataset</font>\n",
    "\n",
    "_The Collection id can be found by looking at the url path in the address bar \n",
    "when viewing your Collection in the CZ CELLxGENE Discover data portal: `/collections/{collection_id}`. You can only add/replace Datasets in private Collections or private revisions of published Collections. In order to edit a published Collection, you must first create a revision of that Collection._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86483731",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_id = \"01234567-89ab-cdef-0123-456789abcdef\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104aea94",
   "metadata": {},
   "source": [
    "<font color='#bc00b0'>(Required) Enter the id of the Dataset to which you wish to upload your datafile</font>\n",
    "\n",
    "_The Dataset id can be found by using the `GET /collections/{collection_id}` endpoint and filtering for the Dataset of interest OR by looking at the url path in the address when viewing your Dataset using the CZ CELLxGENE Explorer browser tool: `/e/{dataset_id}.cxg/`. See heading at top for rules about adding vs updating Datasets._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e9b33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"abcdef01-2345-6789-abcd-ef0123456789\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11de2fe6",
   "metadata": {},
   "source": [
    "### Specify domain (and API url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decaeebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_name = \"cellxgene.cziscience.com\"\n",
    "site_url = f\"https://{domain_name}\"\n",
    "api_url_base = f\"https://api.{domain_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1708156b",
   "metadata": {},
   "source": [
    "### Use API key to obtain a temporary access token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b0481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(api_key_file_path) as f:\n",
    "    api_key = f.read()\n",
    "access_token_path = \"/curation/v1/auth/token\"\n",
    "access_token_url = f\"{api_url_base}{access_token_path}\"\n",
    "res = requests.post(access_token_url, headers={\"x-api-key\": api_key})\n",
    "res.raise_for_status()\n",
    "access_token = res.json().get(\"access_token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea089d0e",
   "metadata": {},
   "source": [
    "##### (optional, debug) verify status code of response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01dc941",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79b1f19",
   "metadata": {},
   "source": [
    "### Retrieve temporary s3 write credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4345fa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_credentials_path = f\"/curation/v1/collections/{collection_id}/datasets/s3-upload-credentials\"\n",
    "url = f\"{api_url_base}{s3_credentials_path}\"\n",
    "bearer_token = f\"Bearer {access_token}\"\n",
    "res = requests.get(url, headers={\"Authorization\": bearer_token})\n",
    "res.raise_for_status()\n",
    "res_content = res.json()\n",
    "print(res_content)\n",
    "access_key_id = res_content[\"Credentials\"][\"AccessKeyId\"]\n",
    "secret_access_key = res_content[\"Credentials\"][\"SecretAccessKey\"]\n",
    "session_token = res_content[\"Credentials\"][\"SessionToken\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14030d8",
   "metadata": {},
   "source": [
    "### Extract formatted upload path from credentials endpoint response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d942695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = res_content[\"Bucket\"]\n",
    "key_prefix = res_content[\"UploadKeyPrefix\"]\n",
    "upload_key = key_prefix + dataset_id\n",
    "print(f\"Full S3 write path is s3://{bucket}/{upload_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f648e0b2",
   "metadata": {},
   "source": [
    "### Upload file using temporary AWS S3 credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15514bce",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "session = boto3.Session(\n",
    "    aws_session_token=session_token,\n",
    "    aws_access_key_id=access_key_id,\n",
    "    aws_secret_access_key=secret_access_key,\n",
    ")\n",
    "session.client(\"s3\").upload_file(\n",
    "    Filename=filename,\n",
    "    Bucket=bucket,\n",
    "    Key=upload_key,\n",
    ")\n",
    "print(f\"Uploaded file {filename} to Dataset {dataset_id} in Collection {collection_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
