{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b68160f6",
   "metadata": {},
   "source": [
    "# Upload a local datafile to add or replace a Dataset in a Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff1ec6e",
   "metadata": {},
   "source": [
    "The script in this notebook performs the upload of a local datafile to a given Collection (as identified by its Collection uuid), where the datafile becomes a Dataset accessible via the Data Portal UI.\n",
    "\n",
    "In order to use this script, you must...\n",
    "- have a Curation API key (obtained from upper-righthand dropdown in the Data Portal UI after logging in)\n",
    "- know the id of the Collection to which you wish to upload the datafile (from `/collections/<collection_id>` in url path in Data Portal UI)\n",
    "\n",
    "**For new Dataset uploads**:\n",
    "- You must decide upon a string tag (the `curator_tag`) to use to uniquely identify the resultant Dataset within its Collection. This tag must *NOT* be the tag of an existing Dataset within this Collection (read on below), and it must _NOT_ conform to the uuid format.\n",
    "\n",
    "**For replacing/updating existing Datasets**:\n",
    "- Uploads to a curator tag for which there already exists a Dataset in the given Collection will result in the existing Dataset being replaced by the new Dataset created from the datafile that you are uploading.\n",
    "- Alternatively, while not necessarily recommended, an existing dataset _may_ be targeted for replacement by using the Dataset's Cellxgene uuid as the tag when writing to S3.\n",
    "- You can only add/replace Datasets in private Collections or revision Collections.\n",
    "\n",
    "For all uploads, the `.h5ad` suffix must be appended to the tag in the S3 write key. See example below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c6c402",
   "metadata": {},
   "source": [
    "#### <font color='#bc00b0'>Please fill in the required values:</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38afd0cd",
   "metadata": {},
   "source": [
    "<font color='#bc00b0'>(Required) Provide the path to your api key file</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7c8c55fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key_file_path = \"../../dev_key\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e84d52e",
   "metadata": {},
   "source": [
    "<font color='#bc00b0'>(Required) Provide the absolute path to the h5ad datafile to upload</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f46e1874",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile_path = \"/Users/danielhegeman/Downloads/valid_schema_2.0.0.h5ad\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104aea94",
   "metadata": {},
   "source": [
    "<font color='#bc00b0'>(Required) Enter your chosen `curator_tag`, which will serve as a unique identifier _within this Collection_ for the resultant Dataset. **Must possess the '.h5ad' suffix**.</font>\n",
    "    \n",
    "_We recommmend using a tagging scheme that 1) makes sense to you, and 2) will help organize and facilitate your \n",
    "automation of future uploads for adding new Datasets and replacing existing Datasets._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b2198be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "curator_tag = \"arbitrary/tag/chosen-by-you323.h5ad\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463870f1",
   "metadata": {},
   "source": [
    "<font color='#bc00b0'>(Required) Enter the uuid of the Collection to which you wish to add this datafile as a Dataset</font>\n",
    "\n",
    "_The Collection uuid can be found by looking at the url path in the address bar \n",
    "when viewing your Collection in the UI of the Data Portal website:_ `collections/{collection_id}`_. You can only add/replace Datasets in private Collections or revision Collections (and not public ones)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f8bb640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_id = \"7c6b3ba5-ddb3-465c-adcf-4596c481b994\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352deec2",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "17d70d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import requests\n",
    "import threading\n",
    "from botocore.credentials import RefreshableCredentials\n",
    "from botocore.session import get_session\n",
    "from datetime import datetime, timezone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50149524",
   "metadata": {},
   "source": [
    "### Import API url helper functions and set url env vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "df457126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set 'site_url' env var to https://cellxgene.dev.single-cell.czi.technology\n",
      "Set 'api_url_base' env var to https://api.cellxgene.dev.single-cell.czi.technology\n"
     ]
    }
   ],
   "source": [
    "%run api_url_env_vars_python.ipynb\n",
    "set_url_env_vars(env=\"dev\")  # or \"dev\" or \"staging\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1708156b",
   "metadata": {},
   "source": [
    "### Import access token helper function and set access token env var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7f3abf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response status code: 201\n",
      "Successfully set 'access_token' env var!\n"
     ]
    }
   ],
   "source": [
    "%run access_token_python.ipynb\n",
    "set_access_token_env_var(api_key_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ae1713",
   "metadata": {},
   "source": [
    "### Define the method for retrieving temporary s3 write credentials. These credentials will only work for _this_ Collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "af25c7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_credentials_path = f\"/curation/v1/collections/{collection_id}/datasets/s3-upload-credentials\"\n",
    "s3_credentials_url = f\"{os.getenv('api_url_base')}{s3_credentials_path}\"\n",
    "s3_cred_headers = {\"Authorization\": f\"Bearer {os.getenv('access_token')}\"}\n",
    "\n",
    "time_zone_info = datetime.now(timezone.utc).astimezone().tzinfo\n",
    "\n",
    "def retrieve_s3_credentials_and_path():\n",
    "    return requests.post(s3_credentials_url, headers=s3_cred_headers).json()\n",
    "\n",
    "def s3_refreshable_creds_cb():\n",
    "    res_data = retrieve_s3_credentials_and_path()\n",
    "    s3_creds = res_data.get(\"Credentials\")\n",
    "    s3_creds_formatted = {\n",
    "        \"access_key\": s3_creds.get(\"AccessKeyId\"),\n",
    "        \"secret_key\": s3_creds.get(\"SecretAccessKey\"),\n",
    "        \"token\": s3_creds.get(\"SessionToken\"),\n",
    "        \"expiry_time\": datetime.fromtimestamp(s3_creds.get(\"Expiration\")).replace(tzinfo=time_zone_info).isoformat(),\n",
    "    }\n",
    "    print(\"Retrieved/refreshed s3 credentials\")\n",
    "    return s3_creds_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdb1fd2",
   "metadata": {},
   "source": [
    "### Define callback method for logging upload progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "45dac5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_progress_cb():\n",
    "    lock = threading.Lock()\n",
    "    uploaded_bytes = 0\n",
    "    prev_percent = 0\n",
    "\n",
    "    def progress_cb(num_bytes):\n",
    "        nonlocal uploaded_bytes\n",
    "        nonlocal prev_percent\n",
    "        should_update_progress_printout = False\n",
    "        \n",
    "        lock.acquire()\n",
    "        uploaded_bytes += num_bytes\n",
    "        percent_of_total_upload = float(\"{:.1f}\".format(uploaded_bytes / filesize * 100))\n",
    "        if percent_of_total_upload > prev_percent:\n",
    "            should_update_progress_printout = True\n",
    "        prev_percent = percent_of_total_upload\n",
    "        lock.release()\n",
    "        \n",
    "        if should_update_progress_printout:\n",
    "            print(f\"{percent_of_total_upload}% uploaded\\r\", end=\"\")\n",
    "            \n",
    "    return progress_cb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8942d14",
   "metadata": {},
   "source": [
    "### Use credential endpoint to retrieve formatted upload path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0982bedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full S3 write path is s3://cellxgene-dataset-submissions-dev/google-oauth2|115898590228662878630/7c6b3ba5-ddb3-465c-adcf-4596c481b994/arbitrary/tag/chosen-by-you323.h5ad\n"
     ]
    }
   ],
   "source": [
    "creds_and_path = retrieve_s3_credentials_and_path()\n",
    "bucket, key_prefix = creds_and_path[\"Bucket\"], creds_and_path[\"UploadKeyPrefix\"]\n",
    "upload_key = key_prefix + curator_tag\n",
    "print(f\"Full S3 write path is s3://{bucket}/{upload_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f648e0b2",
   "metadata": {},
   "source": [
    "### Upload file using temporary s3 credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4c332b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved/refreshed s3 credentials\n",
      "Uploading /Users/danielhegeman/Downloads/valid_schema_2.0.0.h5ad to Collection 7c6b3ba5-ddb3-465c-adcf-4596c481b994 with tag 'arbitrary/tag/chosen-by-you323.h5ad'...\n",
      "100.0% uploaded\n",
      "\n",
      "\u001b[1m\u001b[38;5;10mSUCCESS\u001b[0m\n",
      "\n",
      "File /Users/danielhegeman/Downloads/valid_schema_2.0.0.h5ad successfully uploaded to Collection 7c6b3ba5-ddb3-465c-adcf-4596c481b994 with tag 'arbitrary/tag/chosen-by-you323.h5ad'\n"
     ]
    }
   ],
   "source": [
    "def upload_local_datafile():\n",
    "    session_creds = RefreshableCredentials.create_from_metadata(\n",
    "        metadata=s3_refreshable_creds_cb(),\n",
    "        refresh_using=s3_refreshable_creds_cb,\n",
    "        method=\"sts-assume-role-with-web-identity\",\n",
    "    )\n",
    "    session = get_session()\n",
    "    session._credentials = session_creds\n",
    "    boto3_session = boto3.Session(botocore_session=session)\n",
    "    s3 = boto3_session.client(\"s3\")\n",
    "\n",
    "    filesize = os.path.getsize(filename)\n",
    "\n",
    "    try:\n",
    "        print(f\"Uploading {filename} to Collection {collection_id} with tag '{curator_tag}'...\")\n",
    "        s3.upload_file(\n",
    "            Filename=filename,\n",
    "            Bucket=bucket,\n",
    "            Key=upload_key,\n",
    "            Callback=get_progress_cb(),\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"\\n\\n\\033[1m\\033[38;5;9mFAILED\\033[0m\")  # 'FAILED' in bold red\n",
    "        print(f\"\\n\\n{e}\")\n",
    "    else:\n",
    "        print(\"\\n\\n\\033[1m\\033[38;5;10mSUCCESS\\033[0m\")  # 'SUCCESS' in bold green\n",
    "        print(f\"\\nFile {filename} successfully uploaded to Collection {collection_id} with tag '{curator_tag}'\")\n",
    "\n",
    "upload_local_datafile()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
